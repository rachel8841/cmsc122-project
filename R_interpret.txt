# three types of models: linear, quadratic, logarithmic
# gives r-squared (wait actually it doesn't but maybe it should)
# gives estimates of coefficients, p & t vals for each coeff, SE (either 
#   'robust' or 'normal' depending on heteroscedasticity)
# (does heteroscedasticity test? get and mention that too?)

{For the given year {},} 
{For the given countries {},}
The best fitting model for the relationship between
{yvar} versus {xvar} {with the control} is {}, chosen from either a
linear, quadratic, or logarithmic model.

The model has an adjusted R-squared value of {r2}. The adjusted R-squared value
is a measure of relative predictive power, adjusted for the number of variables.

Lin: 'Here, it means that {}% of the variation in {yvar} can be explained by the
variation in {xvar} {and in control}.'
Quad: 'Here, it means that {}% of the variation in {yvar} can be explained by 
the variation in the square of {xvar} {and in control}.'
Log: 'Here, it means that {}% of the variation in {yvar} can be explained by the
variation in the logarithm of {xvar} {and in control}.'
# Only the dependent/response variable is log-transformed. Exponentiate the coefficient, subtract one from this number, and multiply by 100. This gives the percent increase (or decrease) in the response for every one-unit increase in the independent variable. Example: the coefficient is 0.198. (exp(0.198) â€“ 1) * 100 = 21.9. For every one-unit increase in the independent variable, our dependent variable increases by about 22%.
# https://data.library.virginia.edu/interpreting-log-transformations-in-a-linear-model/


The model gives estimates of the intercepts and coefficients, as well as their 
standard errors and p-values. 
    If SE robust: The standard errors here are robust to account for 
    heteroscedasticity, so they are larger than normal standard errors. Under 
    these conditions, our current method of regression is not the most precise, 
    and the standard errors are inflated to account that.
#The standard error reported is normal or robust depending on whether the y and x variables are homo- or heteroscedastic.

# interpretation of intercept
The y-intercept {} is the expected value of {yvar} when {xvar} is zero 
{and when the control is zero}

# interpretation of coeff(s)
Lin: The coefficient {} represents the change in {yvar} for a one unit increase 
in {xvar}, {holding the control constant} 
Quad: The change in {yvar} for a one unit increase in {xvar} is {the coefficient 
on x} plus two times {the coeff on x^2} times x, {holding the control constant} #this one is super complicated might not make sense to have it
Log: The coefficient {} represents the change in {yvar} for a one percent increase 
in {xvar}, {holding the control constant} 

# find confidence intervals for each thing
do +/- 1.66*SE to get interval
if ci includes 0, say it's not statistically significantly different from 0